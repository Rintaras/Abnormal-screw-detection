# ネジ締め検知システム

## 概要
本システムは、カメラ画像からネジが正しく締まっているかをリアルタイムで判定し、ウィンドウの縁色やバウンディングボックスで状態を可視化するAIシステムです。

### 実装バージョン
1. **従来版（main.py）**: ユーザーが「締めている」「外れている」状態をキー入力でラベル付けし、機械学習モデルがリアルタイムで学習・判定精度を向上させます。
2. **YOLO版（main_yolo.py）**: YOLO（You Only Look Once）を使用した高精度な物体検出システム。事前学習済みモデルからカスタム学習まで対応。

### 追加ツール
- **ラベル付けツール（label_tool.py）**: YOLO学習用のデータセット作成を支援するGUIツール

### 機能比較
| 機能 | 従来版 | YOLO版 |
|------|--------|--------|
| 検出精度 | 中 | 高 |
| 学習速度 | 高速 | 中速 |
| リアルタイム性 | 高 | 高 |
| カスタマイズ性 | 中 | 高 |
| メモリ使用量 | 低 | 中 |
| 締め具合学習 | ✅ | ✅ |
| 物体検出 | ❌ | ✅ |

---

## 使用技術・ライブラリ

### 従来版（main.py）
- **Python 3.x** : メイン言語
- **OpenCV (opencv-python)** : 画像処理、カメラ入力、特徴量抽出、HOG特徴量、エッジ検出、円検出
- **PyQt5** : GUI表示、ウィンドウ縁色制御、画像・バウンディングボックス・テキスト描画、キーイベント取得
- **scikit-learn** : 機械学習（SGDClassifierによるロジスティック回帰）、特徴量の標準化（StandardScaler）
- **NumPy** : 数値計算、配列操作

### YOLO版（main_yolo.py）
- **Python 3.x** : メイン言語
- **OpenCV (opencv-python)** : 画像処理、カメラ入力
- **PyQt5** : GUI表示、ウィンドウ制御、画像・バウンディングボックス描画
- **Ultralytics YOLO** : 物体検出モデル（YOLOv8）
- **PyTorch** : ディープラーニングフレームワーク
- **TorchVision** : 画像変換・前処理
- **NumPy** : 数値計算、配列操作

---

## アルゴリズム・特徴量
### 1. 画像前処理
- カメラ画像の中心付近をクロップし、ネジ頭部分を抽出
- グレースケール変換

### 2. 特徴量抽出
- **ヒストグラム**: クロップ領域の輝度ヒストグラム（32bin）
- **エッジ量**: Cannyエッジ検出で得られるエッジ画素の割合
- **円検出**: HoughCirclesで円形度をスコア化（円が見つかれば1.0、なければ0.0）
- **HOG特徴量**: クロップ領域からHOG（Histogram of Oriented Gradients）特徴量を抽出し、物体の形状やテクスチャを捉える

### 3. バウンディングボックス
- 円検出に成功した場合は、検出円をバウンディングボックス（黄色い円）として描画
- 円検出できない場合は、中心クロップ領域を黄色い矩形で描画

### 4. 機械学習・判定
- **SGDClassifier（ロジスティック回帰）**: ラベル付けされた特徴量を全件バッチ学習
- **StandardScaler**: 特徴量を標準化
- **確率の平滑化**: 直近10フレームの判定確率の移動平均を表示し、0%/100%に張り付きにくくする
- **80%以上で「締め」判定（緑枠）、未満で「外れ」判定（赤枠）**

---

## 実行方法

### 1. 仮想環境の作成と依存関係のインストール（推奨）
```sh
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. プログラムの実行

#### 従来版（特徴量ベース）
```sh
source venv/bin/activate
python main.py
```

#### YOLO版（物体検出）
```sh
source venv/bin/activate
python main_yolo.py
```

#### ラベル付けツール
```sh
source venv/bin/activate
python label_tool.py
```

### 3. システム全体でのインストール（非推奨）
```sh
pip install -r requirements.txt
```

---

## 操作方法

### 従来版（main.py）
- **カメラ選択**: `main.py`の`cv2.VideoCapture()`の引数でカメラデバイス番号を指定（0:内蔵カメラ, 1:USBカメラ, 2:他の外部カメラ...）
- **ラベル付け**:
  - `y`キー：ネジが締まっている状態で押すと「締め」ラベルで学習
  - `n`キー：ネジが外れている状態で押すと「外れ」ラベルで学習
- **ウィンドウ表示**:
  - 締め付け確率（%）と学習回数が画面左上に表示
  - バウンディングボックス（黄色い円または矩形）がネジ部分に描画
  - 判定結果に応じてウィンドウの縁色が緑（締め）または赤（外れ）に変化

### YOLO版（main_yolo.py）
- **カメラ制御**: ボタンでカメラの開始/停止
- **画像キャプチャ**: 学習用画像を保存
- **YOLO学習**: カスタムデータセットでモデルを学習
- **リアルタイム検出**: 検出されたネジにバウンディングボックスを表示
- **ネジ締め具合学習**: Yキー（締め）/Nキー（外れ）でリアルタイム学習
- **ハイブリッド検出**: YOLO物体検出 + 従来版の特徴量ベース学習

### ラベル付けツール（label_tool.py）
- **画像表示**: キャプチャした画像を表示
- **マウス操作**: ドラッグでラベル領域を選択
- **ラベル管理**: 追加・削除・保存機能
- **画像ナビゲーション**: 前の画像/次の画像ボタン

---

## カスタマイズ方法
- **カメラデバイス番号の変更**: `main.py`の`cv2.VideoCapture(0)`の数字を変更
- **特徴量の追加・変更**: `extract_features`関数を編集
- **判定閾値の変更**: `update_frame`内の`if percent >= 80:`の値を変更
- **バウンディングボックスの色や太さ**: `QPen(QColor('yellow'))`や`pen.setWidth(4)`を編集
- **学習モデルの変更**: `SGDClassifier`のパラメータや他の分類器（SVM, RandomForest等）に変更可能
- **確率平滑化ウィンドウ幅**: `self.prob_window`の値を変更

---

## トラブルシューティング
- **カメラが映らない**: デバイス番号を0,1,2...と変更してみてください。USBカメラが正しく接続されているか確認。
- **PermissionError/セキュリティ警告**: macOSの場合は「システム環境設定→セキュリティとプライバシー→カメラ」で「Terminal」や「Python」にカメラ使用許可を与えてください。
- **学習しても判定が変わらない**: 学習データが少ない、特徴量が単純すぎる、カメラ画像が暗い/ブレている等が原因。多様な状態で複数回ラベル付けしてください。
- **0%/100%に張り付く**: 学習データが偏っている、または特徴量が不十分な場合があります。HOG特徴量やヒストグラム、エッジ量などを工夫してください。
- **複数カメラ対応**: `cv2.VideoCapture()`の引数を切り替えることで複数カメラに対応可能。

---

## 参考・発展的な使い方
- **AIモデルの高度化**: 画像認識精度をさらに上げたい場合は、YOLOやTensorFlow, PyTorch等の物体検出モデルを導入可能
- **学習データの保存・再利用**: `X_train`や`y_train`をpickle等で保存・ロードすることで、学習済みモデルの再利用が可能
- **複数ネジ対応**: 複数のネジを同時に検出したい場合は、HoughCirclesの全検出結果を利用し、各ネジごとにバウンディングボックスを描画するよう拡張可能
- **UIの拡張**: カメラ切り替えボタン、学習データの可視化、判定履歴のグラフ表示などもPyQt5で実装可能

---

## ディレクトリ構成例
```
neji/
├── main.py              # メインプログラム
├── requirements.txt     # 必要なPythonパッケージ
├── README.md            # 本ドキュメント
└── ...                  # その他追加ファイル
```

---

## ライセンス・注意事項
- 本システムは研究・実験用途を想定しています。実運用時は十分な検証を行ってください。
- カメラ画像や学習データの取り扱いにはご注意ください。

--- 